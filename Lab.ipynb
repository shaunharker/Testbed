{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import GutenbergSnippetsDataset\n",
    "from classroom import MLPLM, MyLM\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2Sum\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f829e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    path = 'checkpoint84.pt'\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = (\n",
    "        MyLM(\n",
    "            n_ctx=256,\n",
    "            n_vocab_in=256,\n",
    "            d_model=8,\n",
    "            n_layers=2,\n",
    "            d_hidden=4096,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.0,\n",
    "            n_vocab_out=256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergSnippetsDataset()\n",
    "batch_size = 512\n",
    "example_length = model.n_ctx + 1\n",
    "student= Student(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5bf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sqrt(torch.var(p)).item()\n",
    "        # print(idx, pn, mu)\n",
    "    batch_multiplier = 2\n",
    "    lr = lambda n: 1.0e-5\n",
    "    s = lambda n: .25+.5*sin(pi*n/(1000))**2\n",
    "    student.optimizer.state[pn][\"lr\"]           = lambda n: lr(n) * s(n)\n",
    "    student.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    student.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    student.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001 * s(n)\n",
    "    student.optimizer.state[pn][\"update\"]       = lambda n: n%batch_multiplier == 0\n",
    "    student.batch_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.push()\n",
    "time_of_last_baseline = student.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom = Classroom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88848bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom.enroll(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom.students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(student.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## Autocompleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(prompt=None):\n",
    "    for (idx, student) in enumerate(classroom.students):\n",
    "        print(f\"\\n\\nStudent #{idx}\\n==========\")\n",
    "        print(student.autocomplete(prompt=prompt, n_generate=1024))\n",
    "autocomplete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "lag = 1024\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Count(), student.times)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), student.grades)\n",
    "    Z = Fun(TwoWindowFilter(lag=lag), student.baseline_grades)\n",
    "    plot_data.update({f\"grades-{idx}\": (X, Y)})\n",
    "    plot_data.update({f\"baseline-{idx}\": (X, Z)})\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data_2 = {}\n",
    "lag = 8192\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(lambda x, y: x - y, student.grades, student.baseline_grades)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), Y.output, aux=Y)\n",
    "    plot_data_2.update({f\"improvement-{idx}\": (X, Y)})\n",
    "Plot(**plot_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dc1be",
   "metadata": {},
   "source": [
    "## some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in student.optimizer.state:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, student) in enumerate(classroom.students):\n",
    "    print(f\"\\nStudent #{idx}\\n==========\")\n",
    "    N = 8192\n",
    "    n = len(student.times)-1\n",
    "    time = student.time #sum(student.times[:n])\n",
    "    mean_grade = np.mean(np.array(student.grades[n-N:n]))\n",
    "    mean_baseline_grade = np.mean(np.array(student.baseline_grades[n-N:n]))\n",
    "    mean_predicted_grade = np.mean(np.array(student.predicted_grades[n-N:n]))\n",
    "    accuracy = 1.0 - abs(mean_predicted_grade - mean_grade)/(mean_grade)\n",
    "\n",
    "    mean_improvement = mean_grade - mean_baseline_grade\n",
    "    improvement_rate = mean_improvement / (time - time_of_last_baseline)\n",
    "    time_to_level = 0.01/improvement_rate\n",
    "    message = '\\n'.join([\n",
    "        f\"lr                    = {student.optimizer.state['language_model.module.layers.0.weight']['lr'](n)}\",\n",
    "        f\"batch_size            = {student.batch_size}\",\n",
    "        f\"example_length        = {student.example_length}\",\n",
    "        f\"n                     = {n}\",\n",
    "        f\"time                  = {int(time)}s\",\n",
    "        f\"time_of_last_baseline = {int(time_of_last_baseline)}s\",\n",
    "        f\"steps per second      = {(n/time)}\",\n",
    "        f\"mean_baseline_grade   = {mean_baseline_grade}\",\n",
    "        f\"mean_grade            = {mean_grade}\",\n",
    "        f\"mean_predicted_grade  = {mean_predicted_grade}\",\n",
    "        f\"accuracy              = {accuracy}\",\n",
    "        f\"mean_improvement      = {mean_improvement}\",\n",
    "        f\"improvement_rate      = {improvement_rate} per second\",\n",
    "        f\"time_to_level         = {time_to_level}\"\n",
    "    ])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f3879",
   "metadata": {},
   "source": [
    "## saving, histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model, f='checkpoint84.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fece45",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        print(idx, pn, torch.sqrt(torch.var(p)).item())\n",
    "        Y, X = np.histogram(p.detach().cpu().numpy(), bins=int(sqrt(torch.numel(p))), density=True)\n",
    "        print(X.shape, Y.shape)\n",
    "        histograms.append(Plot(**{f\"hist-{idx}\": (X.tolist(), Y.tolist())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3f781",
   "metadata": {},
   "source": [
    "## grade/loss histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98535389",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, X = np.histogram(student.grades, bins=256, range=(.8,1.0), density=True)\n",
    "V, U = np.histogram(student.baseline_grades, bins=256, range=(.8,1.0), density=True)\n",
    "Plot(**{f\"grade-hist\": (X, Y), \"baseline\": (U, V)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
