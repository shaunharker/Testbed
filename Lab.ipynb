{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4a24ab",
   "metadata": {},
   "source": [
    "# Lab Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12749494",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import GutenbergSnippetsDataset\n",
    "from classroom import MLPLM, MyLM\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2Sum\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel\n",
    "from classroom import utf8decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa77de2",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    path = 'checkpoint.pt'\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d536de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = (\n",
    "        MyLM(\n",
    "            n_ctx=256,\n",
    "            n_vocab_in=256,\n",
    "            d_model=8,\n",
    "            n_layers=2,\n",
    "            d_hidden=4096,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.0,\n",
    "            n_vocab_out=256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9963c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model), numel(model)*4/1E9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed9ec4",
   "metadata": {},
   "source": [
    "## initialize student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergSnippetsDataset()\n",
    "batch_size = None\n",
    "example_length = model.n_ctx + 1\n",
    "student= Student(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d10566",
   "metadata": {},
   "source": [
    "## schedule hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25468e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.batch_size=1024\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    batch_multiplier = 1\n",
    "    lr_base = 1e-4\n",
    "    lr = lambda n: lr_base * (n/1000) if n < 1000 else lr_base\n",
    "    s = lambda n: exp(-cos(pi*n/1000))  # sin(pi*n/(1000))**2\n",
    "    student.optimizer.state[pn][\"lr\"]           = lambda n: lr(n) * s(n)\n",
    "    student.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    student.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    student.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001 * s(n)\n",
    "    student.optimizer.state[pn][\"update\"]       = lambda n: n%batch_multiplier == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c6bd0",
   "metadata": {},
   "source": [
    "## initialize baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.push()\n",
    "time_of_last_baseline = student.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25202dea",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16854e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom = Classroom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88848bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom.enroll(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(prompt=None):\n",
    "    for (idx, student) in enumerate(classroom.students):\n",
    "        print(f\"\\n\\nStudent #{idx}\\n==========\")\n",
    "        print(student.autocomplete(prompt=prompt, n_generate=1024))\n",
    "autocomplete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "lag = 1024\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Count(), student.times)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), student.grades)\n",
    "    Z = Fun(TwoWindowFilter(lag=lag), student.baseline_grades)\n",
    "    plot_data.update({f\"grades-{idx}\": (X, Y)})\n",
    "    plot_data.update({f\"baseline-{idx}\": (X, Z)})\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data_2 = {}\n",
    "lag = 64\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(lambda x, y: x - y, student.grades, student.baseline_grades)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), Y.output, aux=Y)\n",
    "    plot_data_2.update({f\"improvement-{idx}\": (X, Y)})\n",
    "Plot(**plot_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c32f3b",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, student) in enumerate(classroom.students):\n",
    "    print(f\"\\nStudent #{idx}\\n==========\")\n",
    "    N = 8192\n",
    "    n = len(student.times)-1\n",
    "    time = student.time\n",
    "    mean_grade = np.mean(np.array(student.grades[n-N:n]))\n",
    "    mean_baseline_grade = np.mean(np.array(student.baseline_grades[n-N:n]))\n",
    "    mean_improvement = mean_grade - mean_baseline_grade\n",
    "    improvement_rate = mean_improvement / (time - time_of_last_baseline)\n",
    "    message = '\\n'.join([\n",
    "        f\"lr                    = {student.optimizer.state['language_model.module.layers.0.weight']['lr'](n)}\",\n",
    "        f\"batch_size            = {student.batch_size}\",\n",
    "        f\"example_length        = {student.example_length}\",\n",
    "        f\"n                     = {n}\",\n",
    "        f\"time                  = {int(time)}s\",\n",
    "        f\"time_of_last_baseline = {int(time_of_last_baseline)}s\",\n",
    "        f\"steps per second      = {(n/time)}\",\n",
    "        f\"mean_baseline_grade   = {mean_baseline_grade}\",\n",
    "        f\"mean_grade            = {mean_grade}\",\n",
    "        f\"mean_improvement      = {mean_improvement}\",\n",
    "        f\"improvement_rate      = {improvement_rate} per second\",\n",
    "    ])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe9998",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c88c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model, f='checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bd9d9",
   "metadata": {},
   "source": [
    "## parameter histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        print(idx, pn, torch.sqrt(torch.var(p)).item())\n",
    "        Y, X = np.histogram(p.detach().cpu().numpy(), bins=int(sqrt(torch.numel(p))), density=True)\n",
    "        print(X.shape, Y.shape)\n",
    "        histograms.append(Plot(**{f\"hist-{idx}\": (X.tolist(), Y.tolist())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92345fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd932e",
   "metadata": {},
   "source": [
    "## batch-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, X = np.histogram(student.grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "V, U = np.histogram(student.baseline_grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "Plot(**{f\"grade-hist\": (X, Y), \"baseline\": (U, V)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e52587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_ctx, model.d_model, model.d_hidden, model.n_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e8670",
   "metadata": {},
   "source": [
    "## example-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a6829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graded_examples():\n",
    "    result = []\n",
    "    for batch_idx in range(16):\n",
    "        x = student.dataset.batch(student.batch_size, student.example_length)\n",
    "        with torch.no_grad():\n",
    "            y = student.model(x)\n",
    "            x = x.cpu().numpy()\n",
    "            y = 1.0 - y.cpu().numpy()\n",
    "            result.append(np.concatenate([x, y], axis=1))\n",
    "    data = np.concatenate(result, axis=0)\n",
    "    result = []\n",
    "    for i in range(data.shape[0]):\n",
    "        bs = bytes(data[i,:-1].astype(int).tolist())\n",
    "        ex = utf8decode(bs).replace('\\n','@').replace('\\r', '@')\n",
    "        if len(ex) < data.shape[1]:\n",
    "            ex = ' '*(data.shape[1]-len(ex)) + ex\n",
    "        result.append((f\"'{ex}' {int(1000*data[i,-1])}\", data[i,-1]))\n",
    "    result = sorted(result, key=lambda x: x[1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graded_examples = get_graded_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b00e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grades = []\n",
    "for example, grade in graded_examples:\n",
    "    print(example, grade)\n",
    "    example_grades.append(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = (0, 1)\n",
    "bins = int(sqrt(len(example_grades)))\n",
    "Y, X = np.histogram(example_grades, bins=bins, range=R, density=True)\n",
    "Plot(**{f\"examples-hist\": (X, Y)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04797a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(example_grades)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
