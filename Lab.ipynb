{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import GutenbergSnippetsDataset\n",
    "from classroom import MLPLM, MyLM\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2Sum\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a83959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    path = 'mylp2-checkpoint.pt'\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1878cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = (\n",
    "        MyLM(\n",
    "            n_ctx=32,\n",
    "            n_vocab_in=256,\n",
    "            d_model=32,\n",
    "            n_layers=1,\n",
    "            d_hidden=8192,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.0,\n",
    "            n_vocab_out=256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPLM\n",
    "if False:\n",
    "    model = (\n",
    "        MLPLM(\n",
    "            n_vocab_in=256,\n",
    "            n_vocab_out=256,\n",
    "            n_ctx=64,\n",
    "            d_model=64,\n",
    "            d_hidden=8192,\n",
    "            nonlinearity=\"sigmoid\").to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergSnippetsDataset()\n",
    "batch_size = 512\n",
    "example_length = model.n_ctx + 1\n",
    "student= Student(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        mu = torch.sqrt(torch.var(p)).item()\n",
    "        print(idx, pn, mu)\n",
    "    batch_multiplier = 64\n",
    "    lr = lambda n: 1.0e-2 / batch_multiplier\n",
    "    s = lambda n: sin(pi*n/(200*61))**2\n",
    "    student.optimizer.state[pn][\"lr\"]           = lambda n: lr(n) * s(n)\n",
    "    student.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    student.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    student.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001 * s(n)\n",
    "    student.optimizer.state[pn][\"update\"]       = lambda n: n%batch_multiplier == 0\n",
    "    student.batch_size=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.push()\n",
    "time_of_last_baseline = student.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e17a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom = Classroom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88848bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom.enroll(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom.students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(student.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## Autocompleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(prompt=None):\n",
    "    for (idx, student) in enumerate(classroom.students):\n",
    "        print(f\"\\n\\nStudent #{idx}\\n==========\")\n",
    "        print(student.autocomplete(prompt=prompt, n_generate=1024))\n",
    "autocomplete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "lag = 1024\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), student.grades)\n",
    "    Z = Fun(TwoWindowFilter(lag=lag), student.baseline_grades)\n",
    "    W = Fun(TwoWindowFilter(lag=lag), student.predicted_grades)\n",
    "    plot_data.update({f\"grades-{idx}\": (X, Y)})\n",
    "    plot_data.update({f\"baseline-{idx}\": (X, Z)})\n",
    "    plot_data.update({f\"predicted-{idx}\": (X, W)})\n",
    "\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data_2 = {}\n",
    "lag = 4096\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(lambda x, y: x - y, student.grades, student.baseline_grades)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), Y.output, aux=Y)\n",
    "\n",
    "    plot_data_2.update({f\"improvement-{idx}\": (X, Y)})\n",
    "\n",
    "\n",
    "Plot(**plot_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d777b4",
   "metadata": {},
   "source": [
    "## some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, student) in enumerate(classroom.students):\n",
    "    print(f\"\\nStudent #{idx}\\n==========\")\n",
    "    N = 8192\n",
    "    n = len(student.times)-1\n",
    "    time = student.time #sum(student.times[:n])\n",
    "    mean_grade = np.mean(np.array(student.grades[n-N:n]))\n",
    "    mean_baseline_grade = np.mean(np.array(student.baseline_grades[n-N:n]))\n",
    "    mean_predicted_grade = np.mean(np.array(student.predicted_grades[n-N:n]))\n",
    "    accuracy = 1.0 - abs(mean_predicted_grade - mean_grade)/(mean_grade)\n",
    "\n",
    "    mean_improvement = mean_grade - mean_baseline_grade\n",
    "    improvement_rate = mean_improvement / (time - time_of_last_baseline)\n",
    "    time_to_level = 0.01/improvement_rate\n",
    "    message = '\\n'.join([\n",
    "        f\"lr                    = {student.optimizer.state['language_model.module.layers.0.weight']['lr'](n)}\",\n",
    "        f\"batch_size            = {student.batch_size}\",\n",
    "        f\"example_length        = {student.example_length}\",\n",
    "        f\"n                     = {n}\",\n",
    "        f\"time                  = {int(time)}s\",\n",
    "        f\"time_of_last_baseline = {int(time_of_last_baseline)}s\",\n",
    "        f\"steps per second      = {(n/time)}\",\n",
    "        f\"mean_baseline_grade   = {mean_baseline_grade}\",\n",
    "        f\"mean_grade            = {mean_grade}\",\n",
    "        f\"mean_predicted_grade  = {mean_predicted_grade}\",\n",
    "        f\"accuracy              = {accuracy}\",\n",
    "        f\"mean_improvement      = {mean_improvement}\",\n",
    "        f\"improvement_rate      = {improvement_rate} per second\",\n",
    "        f\"time_to_level         = {time_to_level}\"\n",
    "    ])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a8aa3",
   "metadata": {},
   "source": [
    "## saving, histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model, f='mylp2-checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916491ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        print(idx, pn, torch.sqrt(torch.var(p)).item())\n",
    "        Y, X = np.histogram(p.detach().cpu().numpy(), bins=int(sqrt(torch.numel(p))), density=True)\n",
    "        print(X.shape, Y.shape)\n",
    "        histograms.append(Plot(**{f\"hist-{idx}\": (X.tolist(), Y.tolist())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601781dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, X = np.histogram(student.grades, bins=128, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "V, U = np.histogram(student.baseline_grades, bins=128, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(**{f\"grade-hist\": (X, Y), \"baseline\": (U, V)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c381f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
