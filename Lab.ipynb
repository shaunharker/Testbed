{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import RandomTokensDataset\n",
    "from classroom import MLPLM\n",
    "from classroom import MLPLM2\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4efd2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_factory(checkpoint=None):\n",
    "    if checkpoint is None:\n",
    "        model = MLPLM(\n",
    "            n_vocab_in=256,\n",
    "            n_vocab_out=256,\n",
    "            n_ctx=32,\n",
    "            d_model=32,\n",
    "            d_hidden=8192,\n",
    "            nonlinearity=\"GELU\").to('cuda')\n",
    "    else:\n",
    "        model = torch.load(checkpoint).to('cuda')\n",
    "    optimizer = AdamW(\n",
    "        parameters=model.parameters(), \n",
    "        lr=lambda n: 1e-7,\n",
    "        alpha=lambda n: 0.0 if n == 0 else 0.0,\n",
    "        beta1=lambda n: 0.9,\n",
    "        beta2=lambda n: 0.999,\n",
    "        weight_decay=lambda n: 0.01,\n",
    "        n=0)    \n",
    "    dataset = BytesDataset(path='/home/sharker/data/gutenberg.utf8')\n",
    "    batch_size = 1024\n",
    "    example_length = model.n_ctx + 1\n",
    "    return Student(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        example_length=example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b22d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d035c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classroom = Classroom()\n",
    "student = student_factory()\n",
    "classroom.enroll(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b1c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.model, numel(student.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## Autocompleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student.autocomplete(n_generate=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364617b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.push()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## Training Visualization Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(KalmanFilter1D(), student.grades)\n",
    "    Z = Fun(KalmanFilter1D(), student.baseline_grades)\n",
    "    plot_data.update({f\"grades-{idx}\": (X, Y)})\n",
    "    plot_data.update({f\"baseline-{idx}\": (X, Z)})\n",
    "\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Sum(), student.times)\n",
    "    Y = Fun(KalmanFilter1D(), student.relative_grades)\n",
    "    plot_data.update({f\"rate-{idx}\": (X, Y)})\n",
    "\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166500bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.step/student.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def evolution(classroom):\n",
    "    relative_grades = {student: Fun(TwoWindowFilter(lag=1024), student.relative_grades) for student in classroom.students}\n",
    "    while True:\n",
    "        await asyncio.sleep(60.0)\n",
    "        ranked_students = sorted([student for student in classroom.students], key=lambda s: relative_grades[s].output[-1])\n",
    "        top_student = ranked_students[-1]\n",
    "        bot_student = ranked_students[0]\n",
    "        if bot_student != top_student:\n",
    "            classroom.graduate(bot_student)\n",
    "            del relative_grades[bot_student]\n",
    "        clone = top_student.clone()\n",
    "        clone.mutate()\n",
    "        classroom.enroll(clone)\n",
    "        relative_grades[clone] = Fun(TwoWindowFilter(lag=1024), clone.relative_grades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6676064",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = {name: p for (name, p) in student.model.named_parameters()}\n",
    "brakes = lambda n: 1e-8 # 1e-6*sin(3.14159*n/8192)**2\n",
    "student.optimizer.lr[pd['LM.F.layers.0.weight']] = lambda n: brakes(n)\n",
    "student.optimizer.lr[pd['LM.F.layers.2.F.layers.0.weight']] = lambda n: brakes(n)\n",
    "student.optimizer.lr[pd['LM.F.layers.2.F.layers.1.weight']] = lambda n: brakes(n)\n",
    "student.optimizer.lr[pd['LM.F.layers.2.F.layers.1.bias']] = lambda n: brakes(n)\n",
    "student.optimizer.lr[pd['LM.F.layers.2.F.layers.3.weight']] = lambda n: brakes(n)\n",
    "student.optimizer.lr[pd['LM.F.layers.2.F.layers.3.bias']] = lambda n: brakes(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd05ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model, f='checkpoint.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
