{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "from time import time, sleep\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from testbed import UTF8Dataset, MLPLM, TransformerLM, AdamW, Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5095193",
   "metadata": {},
   "source": [
    "## Scheduling helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = lambda c: lambda step: c\n",
    "linear_warmup_then_decay = lambda lr, warmup: lambda n: lr*(n/warmup) if n < warmup else lr*(warmup/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b87b2",
   "metadata": {},
   "source": [
    "## MLP Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPLM(n_vocab_in=256, n_vocab_out=256, n_ctx=64,\n",
    "              d_model=64, d_hidden=8192, nonlinearity=\"GELU\").to('cuda')\n",
    "\n",
    "optimizer = AdamW(parameters=model.parameters(), eps=constant(1e-4), \n",
    "                  lr=linear_warmup_then_decay(lr=5e-5,warmup=256), \n",
    "                  beta1=constant(0.9), beta2=constant(0.999),\n",
    "                  weight_decay=constant(0.01), initial_step=0)\n",
    "\n",
    "dataset = UTF8Dataset()\n",
    "\n",
    "config = {\"model\": model, \"optimizer\": optimizer, \"dataset\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f230087",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader, writer = await asyncio.open_connection('127.0.0.1', 8888)\n",
    "async def train(n_steps, batch_size, example_length, stream):\n",
    "    try:\n",
    "        for _ in range(n_steps):\n",
    "            await asyncio.sleep(.01)\n",
    "            loss = np.sum(learner.step(batch_size, example_length))/batch_size\n",
    "            stream.write(bytes(struct.pack(\"f\", value)))\n",
    "            await stream.drain()\n",
    "    except Exception as e:\n",
    "        return e\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "output_notebook()\n",
    "import time, math\n",
    "from threading import Thread, Event, Lock\n",
    "\n",
    "class Ticker:\n",
    "    def __init__(self, x='time', y='mean_loss', stream):\n",
    "        self.stream = stream\n",
    "        self.data = []\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.bokeh = {}\n",
    "        self.task = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        self.bokeh[\"figure\"] = figure(x_axis_label=self.x.replace('_',' '),\n",
    "                                      y_axis_label=self.y.replace('_',' '),\n",
    "                                      tools=\"pan,wheel_zoom,box_zoom,reset\")\n",
    "        self.bokeh[\"figure\"].axis.major_label_text_font_size = \"24px\"\n",
    "        self.bokeh[\"data\"] = self.bokeh[\"figure\"].line([],[])\n",
    "        self.bokeh_handle = show(self.bokeh[\"figure\"], notebook_handle=True)\n",
    "        if self.task is None:\n",
    "            self.task = asyncio.create_task(self._update_loop(self.x, self.y, self.bokeh,\n",
    "                                                              self.bokeh_handle, self.stream)\n",
    "        return \"\"\n",
    "\n",
    "    def __del__(self):\n",
    "        self.task.cancel()\n",
    "\n",
    "    @staticmethod\n",
    "    async def _update_loop(x, y, bokeh, bokeh_handle, reader):\n",
    "        tick = 0\n",
    "        try:\n",
    "            await asyncio.sleep(1.0)\n",
    "            data = {x: [item[x] for item in trainer.metrics[tick:]], y: [item[y] for item in trainer.metrics[tick:]]}\n",
    "            if len(data) > 0:\n",
    "                if stop_event.is_set():\n",
    "                    break\n",
    "                bokeh[\"data\"].data_source.stream({'x': data[x], 'y': data[y]})\n",
    "                tick = len(trainer.metrics)\n",
    "            push_notebook(handle=bokeh_handle)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = asyncio.create_task(train(2**20, 256, 65, 'log.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7348da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b108d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 1 log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0b4fb",
   "metadata": {},
   "source": [
    "## Transformer Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLM(n_vocab_in=256, n_vocab_out=256, max_ctx=128, d_model=256,\n",
    "                      d_k=16, d_v=16, n_heads=16, d_hidden=256, n_layers=8, p_dropout_embedding=0.0,\n",
    "                      p_dropout_attn_mat=0.0, p_dropout_attn_out=0.0, p_dropout_mlp=0.0).to('cuda')\n",
    "\n",
    "optimizer = AdamW(parameters=model.parameters(), eps=constant(1e-4),\n",
    "                  lr=linear_warmup_then_decay(lr=1e-4,warmup=10000), \n",
    "                  beta1=constant(0.9), beta2=constant(0.999), weight_decay=constant(0.01),\n",
    "                  initial_step=0)\n",
    "\n",
    "dataset = UTF8Dataset()\n",
    "\n",
    "config = {\"model\": model, \"optimizer\": optimizer, \"dataset\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.step(256,33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc2d98",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = StatsTicker(trainer,  x='step', y='mean_loss')\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update(\"optimizer\", lr=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update(\"dataset\", batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "more = ''.join(list(trainer.autocomplete(result[:128],n_generate=256, max_ctx=128)))\n",
    "print(more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gibberish.txt', 'w') as outfile:\n",
    "    outfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def foo():\n",
    "    global result\n",
    "    more = ''.join(list(trainer.autocomplete(n_generate=256, max_ctx=128)))\n",
    "    result += more\n",
    "    with open('gibberish.txt', 'a') as outfile:\n",
    "        outfile.write(more)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79670963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2400):\n",
    "    sleep(15)\n",
    "    t = asyncio.create_task(foo())\n",
    "    await t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8baa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(\"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load('checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "### SmoothPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "def smoother(X, Y, lag):\n",
    "    Y = np.cumsum(Y)\n",
    "    return X[lag:], (Y[lag:] - Y[:-lag])/lag\n",
    "\n",
    "def gsmoother(X, Y, lag):\n",
    "    X = X[lag:-lag]\n",
    "    Y = scipy.ndimage.gaussian_filter1d(Y, sigma=lag)[lag:-lag]\n",
    "    return (X, Y)\n",
    "\n",
    "class SmoothPlot(LinePlot):\n",
    "    def __init__(self, trainer, lag=100, log=None):\n",
    "        L = np.array([[x['step'],x['mean_loss']] for x in trainer.metrics])\n",
    "        n = len(L[:,0])\n",
    "        k = n//1000 + 1\n",
    "        X = L[:,0]\n",
    "        Y = L[:,1]\n",
    "        X,Y = gsmoother(X, Y, lag)\n",
    "        X = X[::k]\n",
    "        Y = Y[::k]\n",
    "        if log:\n",
    "            X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)\n",
    "\n",
    "class GaussianSmoothedLossRate(LinePlot):\n",
    "    def __init__(self, trainer, lag=100, log=None):\n",
    "        L = np.array([[x['step'],x['mean_loss']] for x in trainer.metrics])\n",
    "        X = L[1:,0]\n",
    "        Y = -L[1:,1] + L[:-1,1]\n",
    "        X,Y = gsmoother(X, Y, lag)\n",
    "        if log:\n",
    "            X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmoothPlot(trainer, lag=10, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianSmoothedLossRate(trainer, lag=10000, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9414477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
