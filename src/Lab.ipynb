{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.optim import AdamW, SGD\n",
    "from testbed import TextDataset, Trainer, Net0, Net1, Net2, Net3, Net4, Transformer\n",
    "from testbed.optim import Sonny\n",
    "from testbed.util import decode_broken_utf8, default_device, numel\n",
    "from testbed.gui import Plot, StatsTicker, ParameterInspector, Histogram, SmoothPlot, LinePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e240cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162db02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_memory():\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0) \n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    f = r-a  # free inside reserved\n",
    "    print(f\"Total {t}. Reserved {r}. Allocated {a}. Free {f}.\")\n",
    "    return (f, a, r, t) # code smell?\n",
    "\n",
    "def memory_allocated():\n",
    "    return torch.cuda.memory_allocated(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_name == \"Net0\":\n",
    "    num_input_classes= 256 # 256 possible UTF-8 bytes\n",
    "    embedding_dim = 32 # Dimension of embedding space. An embedding layer has 256 points in this space.\n",
    "    context_length = 32 # Number of sequential bytes visible to model (i.e. in the context)\n",
    "    num_hidden = 8192 # Hyperparameter for neural network\n",
    "    num_output_classes = 256 # 256 possible UTF-8 bytes\n",
    "    model = Net0(num_input_classes=num_input_classes,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                 context_length=context_length,\n",
    "                 num_hidden=num_hidden,\n",
    "                 num_output_classes=num_output_classes,\n",
    "                 nonlinearity=\"sigmoid\").to(default_device())\n",
    "    example_length = context_length + 1\n",
    "    dataset = TextDataset(example_length=example_length)\n",
    "    batch_size = 512 # batch size (i.e. examples per batch)\n",
    "    OptimizerType = Sonny\n",
    "    optimizer_kwargs = {\"eps\": 1e-8, \"weight_decay\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc167e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_name == \"Net3\":\n",
    "    embedding_dim = 2\n",
    "    context_length = 32\n",
    "    num_hidden1 = 64\n",
    "    num_hidden2 = 64\n",
    "    model = Net3(embedding_dim=embedding_dim,\n",
    "                 context_length=context_length,\n",
    "                 num_hidden1=num_hidden1,\n",
    "                 num_hidden2=num_hidden2).to(default_device())\n",
    "    example_length = context_length + 1\n",
    "    dataset = TextDataset(example_length=example_length)\n",
    "    batch_size = 512\n",
    "    OptimizerType = Sonny\n",
    "    optimizer_kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd38623",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_name == \"Net4\":\n",
    "    num_input_classes= 256 # 256 possible UTF-8 bytes\n",
    "    embedding_dim = 128 # Dimension of embedding space. An embedding layer has 256 points in this space.\n",
    "    context_length = 128 # Number of sequential bytes visible to model (i.e. in the context)\n",
    "    num_hidden = 4096 # Hyperparameter for neural network\n",
    "    num_output_classes = 256 # 256 possible UTF-8 bytes\n",
    "    model = Net4(num_input_classes=num_input_classes,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                 context_length=context_length,\n",
    "                 num_hidden=num_hidden,\n",
    "                 num_output_classes=num_output_classes,\n",
    "                 nonlinearity=\"GELU\").to(default_device())\n",
    "    example_length = context_length + 1\n",
    "    dataset = TextDataset(example_length=example_length)\n",
    "    batch_size = 8192 # batch size (i.e. examples per batch)\n",
    "    OptimizerType = Sonny\n",
    "    optimizer_kwargs = {\"eps\": 1e-4, \n",
    "                        \"lr\": .0001, \n",
    "                        \"beta1\": .9, \n",
    "                        \"beta2\": .999,\n",
    "                        \"weight_decay\": 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c71de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_name == \"Transformer\":\n",
    "    model = Transformer(\n",
    "        n_vocab=256,\n",
    "        max_ctx=512,\n",
    "        d_model=64,\n",
    "        n_heads=8,\n",
    "        d_ff=2048,\n",
    "        n_layers=6).to(default_device())\n",
    "    example_length = model.max_ctx + 1\n",
    "    dataset = TextDataset(example_length=example_length)\n",
    "    batch_size = 300 # batch size (i.e. examples per batch)\n",
    "    OptimizerType = Sonny\n",
    "    optimizer_kwargs = {\"eps\": 1e-4, \n",
    "                        \"lr\": .0001, \n",
    "                        \"beta1\": .9, \n",
    "                        \"beta2\": .999,\n",
    "                        \"weight_decay\": 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, \n",
    "                  example_length=example_length, \n",
    "                  batch_size=batch_size,\n",
    "                  OptimizerType=OptimizerType,\n",
    "                  optimizer_kwargs=optimizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model), model.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, p) in model.named_parameters():\n",
    "    print(name, p.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = StatsTicker(trainer, kind='line')\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6101a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsTicker(trainer, x='compute_time', y='compute_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02751910",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_optimizer_settings(lr=.0001, beta1=.9, beta2=.999, batch_size=8192*32, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d367182",
   "metadata": {},
   "outputs": [],
   "source": [
    "1788*512*128/248.94 * 20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "    print(torch.min(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.losses[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.autocomplete()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "### SmoothPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array([[x['compute_time'],x['mean_loss']] for x in trainer.losses])\n",
    "X = L[:,0]\n",
    "Y = L[:,1]\n",
    "def smoother(data, lag):\n",
    "    cs = np.cumsum(data)\n",
    "    return (cs[lag:] - cs[:-lag])/lag\n",
    "\n",
    "class SmoothPlot(LinePlot):\n",
    "    def __init__(self, X=None, Y=None, lag=100, log=None):\n",
    "        if X is not None:\n",
    "            if Y is None:\n",
    "                Y = np.array(X)\n",
    "                X = np.array(range(len(X)))\n",
    "            else:\n",
    "                X = np.array(X)\n",
    "                Y = np.array(Y)\n",
    "            X = X[lag:]\n",
    "            Y = smoother(Y, lag)\n",
    "            if log:\n",
    "                X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)\n",
    "SmoothPlot(X, Y, lag=100, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "24*3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8375a1",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf183daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torch.nn import Module, Embedding, Linear, CrossEntropyLoss, Softmax\n",
    "\n",
    "def speed_test(B=8192, m=4096, n=1024):\n",
    "    L = Linear(n, m).to('cuda')\n",
    "    x = torch.randn(B, n, device='cuda')\n",
    "    t = benchmark.Timer(\n",
    "        stmt='L(x)',\n",
    "        globals={'L': L, 'x': x})\n",
    "    T = t.timeit(10)\n",
    "    print(f'Benchmark:  {T.median* 1e6:>5.1f} us, {B*m*n / (1E9*T.median)} GFLOPS')\n",
    "    return T.median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550395a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torch.nn import Module, Embedding, Linear, CrossEntropyLoss, Softmax\n",
    "\n",
    "def speed_test(B=8192, m=4096, n=1024):\n",
    "    L = Linear(n, m).half().to('cuda')\n",
    "    x = torch.randn(B, n, device='cuda', dtype=torch.float16)\n",
    "    t = benchmark.Timer(\n",
    "        stmt='L(x)',\n",
    "        globals={'L': L, 'x': x})\n",
    "    T = t.timeit(20)\n",
    "    print(f'Benchmark:  {T.median* 1e6:>5.1f} us, {B*m*n / (1E9*T.median)} GFLOPS')\n",
    "    return T.median\n",
    "\n",
    "speed_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6db27",
   "metadata": {},
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer(\"Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\" Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc5b470",
   "metadata": {},
   "source": [
    "idea: compute polynomial activation functions using horners method with trainable parameter coefficients.\n",
    "\n",
    "by stone or weierstrass or some other mad-dog mathematician i ought to remember, we know that polynomials converge uniformly to any desired function of sufficient regularity... I want to say L2, but then the concept of uniform has to be tweaked, perhaps uniformly almost everywhere, or for every delta we can exclude a set of measure delta and on what remains we have uniform convergence. \n",
    "\n",
    "but never mind these mathematical technicalities for once because we don't need to care, we just need to know the central idea is sound. It is. So we can do this. We don't have to join a religious group of GELU vs ReLU vs sigmoid or whatever. Let it choose itself.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, p) in model.named_parameters():\n",
    "    #if name == 'nonlinear.coefs':\n",
    "    print(p.shape, p)\n",
    "    print(torch.any(torch.isnan(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "for (name, p) in model.named_parameters():\n",
    "    if name == 'nonlinear.coefs':\n",
    "        c = p.detach().cpu().numpy()  \n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497bbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .001\n",
    "X = np.arange(h,1,h)\n",
    "Y = sum( c[i] * X**i for i in range(len(c)))\n",
    "LinePlot(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b08bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .01\n",
    "X = np.arange(-6.28+h,6.28,h)\n",
    "Y = sum( c[i] * np.sin(X)**i for i in range(len(c)))\n",
    "LinePlot(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc632b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "n = randrange(p.shape[-1])\n",
    "for (name, p) in model.named_parameters():\n",
    "    if name == 'nonlinear.coefs':\n",
    "        c = p[:,n].detach().cpu().numpy()  \n",
    "        print(c.shape)\n",
    "\n",
    "h = .001\n",
    "X = np.arange(0,1+h,h)\n",
    "Y = sum( c[i] * X**i for i in range(len(c)))\n",
    "LinePlot(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
