{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "from time import time, sleep\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from testbed import ShortDataset, ByteDataset, Trainer, Net0, Net1, Net2, Net3, Net4, Transformer\n",
    "from testbed.optimizer import Sonny\n",
    "from testbed.util import default_device, numel\n",
    "from testbed.gui import Plot, StatsTicker, ParameterInspector, Histogram, SmoothPlot, LinePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e240cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"UTF8Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if network_name == \"Net0\":\n",
    "    num_input_classes= 256 # 256 possible UTF-8 bytes\n",
    "    embedding_dim = 32 # Dimension of embedding space. An embedding layer has 256 points in this space.\n",
    "    context_length = 32 # Number of sequential bytes visible to model (i.e. in the context)\n",
    "    num_hidden = 8192 # Hyperparameter for neural network\n",
    "    num_output_classes = 256 # 256 possible UTF-8 bytes\n",
    "    model = Net0(num_input_classes=num_input_classes,\n",
    "                 embedding_dim=embedding_dim,\n",
    "                 context_length=context_length,\n",
    "                 num_hidden=num_hidden,\n",
    "                 num_output_classes=num_output_classes,\n",
    "                 nonlinearity=\"sigmoid\").to(default_device())\n",
    "    example_length = context_length + 1\n",
    "    dataset = ByteDataset(example_length=example_length)\n",
    "    batch_size = 512 # batch size (i.e. examples per batch)\n",
    "    OptimizerType = Sonny\n",
    "    optimizer_kwargs = {\"eps\": 1e-8, \"weight_decay\": 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8_transformer_config = {\n",
    "    \"model\": {\n",
    "        \"type\": Transformer,\n",
    "        \"kwargs\": {\n",
    "            \"n_vocab\": 256,\n",
    "            \"max_ctx\": 128,\n",
    "            \"d_model\": 1024,\n",
    "            \"n_heads\": 8,\n",
    "            \"d_ff\": 8192,\n",
    "            \"n_layers\": 8}},\n",
    "    \"optimizer\": {\n",
    "        \"type\": Sonny,\n",
    "        \"kwargs\": {\n",
    "            \"eps\": 1e-4, \n",
    "            \"lr\": .0001, \n",
    "            \"beta1\": .9, \n",
    "            \"beta2\": .999,\n",
    "            \"weight_decay\": 0.01,\n",
    "            \"warmup\": 10000}},\n",
    "    \"dataset\": {\n",
    "        \"type\": ByteDataset,\n",
    "        \"kwargs\": {\n",
    "            \"batch_size\": 256,\n",
    "            \"example_length\": 32+1}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utf8_transformer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = StatsTicker(trainer.metrics,  x='step', y='mean_loss', kind='line')\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb38750",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(''.join(list(trainer.autocomplete(n_generate=256, max_ctx=32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d549a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "while time() - t < 1000:\n",
    "    sleep(60)\n",
    "    print(f\"{int(time() - t)//60} minutes, step={trainer.metrics[-1]['step']},\"\n",
    "          f\" mean_loss = {trainer.metrics[-1]['mean_loss']}\")\n",
    "    print(''.join(list(trainer.autocomplete(n_generate=256, max_ctx=32))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8baa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics[-1][\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2137da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ccaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsTicker(trainer.metrics, x='time', y='energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e5ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update(\"optimizer\", lr=.0001, beta1=.9, beta2=.999, batch_size=8, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(model.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = trainer.metrics[-1]\n",
    "print(m, m[\"batch_losses\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def floprecurse(d, s):\n",
    "    results = []\n",
    "    if type(d) == dict:\n",
    "        try:\n",
    "            if \"time\" in d and \"energy\" in d:\n",
    "                results.append(f'\"{s}\": {{\"time\": {d[\"time\"]}, \"energy\": {d[\"energy\"]},'\n",
    "                               f' \"tflops\"= {d[\"energy\"]/d[\"time\"]/1E12}}}')\n",
    "        except:\n",
    "            pass\n",
    "        for (k, v) in d.items():\n",
    "            results = results + floprecurse(v, f\"{s}.{k}\")\n",
    "    if type(d) == list:\n",
    "        for (k, v) in enumerate(d):\n",
    "            results = results + floprecurse(v, f\"{s}.{k}\")\n",
    "    return results            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63abb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = trainer.losses[-1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ccfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = floprecurse(d, \"root\")\n",
    "for a in A:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "### SmoothPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array([[x['step'],x['mean_loss']] for x in trainer.losses])\n",
    "X = L[:,0]\n",
    "Y = L[:,1]\n",
    "def smoother(data, lag):\n",
    "    cs = np.cumsum(data)\n",
    "    return (cs[lag:] - cs[:-lag])/lag\n",
    "\n",
    "class SmoothPlot(LinePlot):\n",
    "    def __init__(self, X=None, Y=None, lag=100, log=None):\n",
    "        if X is not None:\n",
    "            if Y is None:\n",
    "                Y = np.array(X)\n",
    "                X = np.array(range(len(X)))\n",
    "            else:\n",
    "                X = np.array(X)\n",
    "                Y = np.array(Y)\n",
    "            X = X[lag:]\n",
    "            Y = smoother(Y, lag)\n",
    "            if log:\n",
    "                X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)\n",
    "SmoothPlot(X, Y, lag=100, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a533a",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedcedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def timing_study():\n",
    "\n",
    "    n_vocab=50257\n",
    "    max_ctx=1024\n",
    "    d_model=1024\n",
    "    n_heads=32\n",
    "    d_ff=4096,\n",
    "    n_layers=4\n",
    "    n_ctx = 1024\n",
    "    d_head = d_model // n_heads\n",
    "    assert d_model == n_heads * d_head\n",
    "    torch.cuda.synchronize()\n",
    "    data = defaultdict(lambda: defaultdict(float))\n",
    "    X = torch.randn(n_ctx, d_model, device='cuda')\n",
    "    Q = X\n",
    "    K = X\n",
    "    V = X\n",
    "    input_shape = X.shape\n",
    "    def split_heads(x):\n",
    "        return x.view(x.shape[:-1] + (n_heads, d_head)).transpose(-2, -3).contiguous()\n",
    "    def merge_heads(x):\n",
    "        x = x.transpose(-2,-3).contiguous()\n",
    "        return x.view(x.shape[:-2] + (d_model,))\n",
    "    additive_mask = 1.0-1.0/torch.tril(torch.ones(n_ctx,n_ctx, device=X.device))\n",
    "    additive_mask = torch.zeros(n_ctx,n_ctx, device=X.device)\n",
    "    @torch.no_grad()\n",
    "    def compute(Q0,K0,V0,data, N):\n",
    "        torch.cuda.synchronize()\n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            Q = split_heads(Q0)/math.sqrt(d_head)\n",
    "            K = split_heads(K0)\n",
    "            V = split_heads(V0)\n",
    "            torch.cuda.synchronize()\n",
    "            data[\"split_heads\"][\"data\"] += torch.numel(Q) + torch.numel(K) + torch.numel(V)\n",
    "        data[\"split_heads\"][\"energy\"] += 3.0 * N * (torch.numel(Q) + torch.numel(K) + torch.numel(V))\n",
    "        data[\"split_heads\"][\"time\"] += time() - t\n",
    "\n",
    "\n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            QKT = torch.matmul(Q, K.transpose(-1,-2)).contiguous()\n",
    "            torch.cuda.synchronize()\n",
    "            data[\"matmul(Q,K^T)\"][\"data\"] += torch.numel(Q) + torch.numel(K) + torch.numel(QKT)\n",
    "        data[\"matmul(Q,K^T)\"][\"energy\"] += 3.0 * N * torch.numel(Q) * n_ctx\n",
    "        data[\"matmul(Q,K^T)\"][\"time\"] += time() - t\n",
    "\n",
    "        #print(f\"Q.shape={Q.shape}\")\n",
    "        #print(f\"K.shape={Q.shape}\")\n",
    "        #print(f\"QKT.shape={QKT.shape}\")\n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            Z = QKT + additive_mask\n",
    "        torch.cuda.synchronize()\n",
    "        data[\"masking_attention\"][\"data\"] += N*(torch.numel(Z) + torch.numel(QKT) + torch.numel(additive_mask))\n",
    "        data[\"masking_attention\"][\"energy\"] += 3.0 * N * 4.0 * (torch.numel(Z)) # ?\n",
    "        data[\"masking_attention\"][\"time\"] += time() - t\n",
    "    \n",
    "\n",
    "#         t = time()\n",
    "#         for _ in range(N):\n",
    "#             (Zmax, _) = torch.max(Z,dim=-1,keepdim=True)\n",
    "#             Z = Z - Zmax # as in GPT-2\n",
    "#             EZ = torch.exp(Z)\n",
    "#             sumEZ = torch.sum(EZ,dim=-1,keepdim=True)\n",
    "#             A = EZ/sumEZ\n",
    "#             assert A.shape == EZ.shape\n",
    "#             torch.cuda.synchronize()\n",
    "#         data[\"compute_attention\"][\"energy\"] += 3.0 * N * 5.0 * (torch.numel(A)) # ?\n",
    "#         data[\"compute_attention\"][\"time\"] += time() - t\n",
    "        softmax = torch.nn.Softmax(dim=-1)\n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            A = softmax(Z)\n",
    "            torch.cuda.synchronize()\n",
    "            data[\"compute_attention\"][\"data\"] += torch.numel(Z) + torch.numel(A)\n",
    "        data[\"compute_attention\"][\"energy\"] += 3.0 * N * 5.0 * (torch.numel(A)) # ?\n",
    "        data[\"compute_attention\"][\"time\"] += time() - t\n",
    "        \n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            AV = torch.matmul(A,V)\n",
    "            torch.cuda.synchronize()\n",
    "            data[\"matmul(A,V)\"][\"data\"] += torch.numel(A) + torch.numel(V) + torch.numel(AV)\n",
    "        data[\"matmul(A,V)\"][\"energy\"] += 3.0 * N * (torch.numel(A) * d_head)\n",
    "        data[\"matmul(A,V)\"][\"time\"] += time() - t\n",
    "\n",
    "        t = time()\n",
    "        for _ in range(N):\n",
    "            mergedAV = merge_heads(AV)\n",
    "            torch.cuda.synchronize()\n",
    "            data[\"merge_heads\"][\"data\"] += torch.numel(AV)\n",
    "        data[\"merge_heads\"][\"energy\"] += 3.0 * N * (torch.numel(AV))\n",
    "        data[\"merge_heads\"][\"time\"] += time() - t\n",
    "    start_time = time()\n",
    "    idx = 0\n",
    "    while time() < start_time + 30:\n",
    "        compute(Q,K,V,data,64)\n",
    "        idx = idx + 1\n",
    "    return (idx, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, data = timing_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ccd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef89fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttime = sum(v[\"time\"] for (k,v) in data.items())\n",
    "tenergy = sum(v[\"energy\"] for (k,v) in data.items())\n",
    "\n",
    "for (k,v) in data.items():\n",
    "    print(k, v[\"time\"]/ttime, v[\"energy\"]/v[\"time\"]/1E12, v[\"data\"]/v[\"time\"]/1E9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenergy/ttime/1E12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9757f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.nn.Softmax(dim=-1)\n",
    "x = 1.0-1.0/torch.tril(torch.ones(5,5, device='cpu'))\n",
    "s(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2102fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
