{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import array, struct\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "from time import time, sleep\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from testbed import UTF8Dataset, MLPLM, TransformerLM, AdamW, Learner, MagicList, StatsTicker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38af5a3",
   "metadata": {},
   "source": [
    "## Scheduling helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = lambda c: lambda step: c\n",
    "linear_warmup_then_decay = lambda lr, warmup: lambda n: lr*(n/warmup) if n < warmup else lr*(warmup/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3ba18",
   "metadata": {},
   "source": [
    "## MLP Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPLM(n_vocab_in=256, n_vocab_out=256, n_ctx=64,\n",
    "              d_model=64, d_hidden=8192, nonlinearity=\"GELU\").to('cuda')\n",
    "\n",
    "optimizer = AdamW(parameters=model.parameters(), eps=constant(1e-4), \n",
    "                  lr=linear_warmup_then_decay(lr=5e-5,warmup=256), \n",
    "                  beta1=constant(0.9), beta2=constant(0.999),\n",
    "                  weight_decay=constant(0.01), initial_step=0)\n",
    "\n",
    "dataset = UTF8Dataset()\n",
    "\n",
    "config = {\"model\": model, \"optimizer\": optimizer, \"dataset\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b80ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MagicList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train(n_steps, batch_size, example_length, metrics):\n",
    "    try:\n",
    "        for step in range(n_steps):\n",
    "            await asyncio.sleep(.01)\n",
    "            loss = np.sum(learner.step(batch_size, example_length))/batch_size\n",
    "            metrics.append(loss)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.create_task(train(2**20, 256, 65, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75020d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StatsTicker(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0dcd7",
   "metadata": {},
   "source": [
    "## Transformer Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb4fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLM(n_vocab_in=256, n_vocab_out=256, max_ctx=128, d_model=256,\n",
    "                      d_k=16, d_v=16, n_heads=16, d_hidden=256, n_layers=8, p_dropout_embedding=0.0,\n",
    "                      p_dropout_attn_mat=0.0, p_dropout_attn_out=0.0, p_dropout_mlp=0.0).to('cuda')\n",
    "\n",
    "optimizer = AdamW(parameters=model.parameters(), eps=constant(1e-4),\n",
    "                  lr=linear_warmup_then_decay(lr=1e-4,warmup=10000), \n",
    "                  beta1=constant(0.9), beta2=constant(0.999), weight_decay=constant(0.01),\n",
    "                  initial_step=0)\n",
    "\n",
    "dataset = UTF8Dataset()\n",
    "\n",
    "config = {\"model\": model, \"optimizer\": optimizer, \"dataset\": dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.step(256,33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c01c727",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = StatsTicker(trainer,  x='step', y='mean_loss')\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update(\"optimizer\", lr=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.update(\"dataset\", batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2937c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "more = ''.join(list(trainer.autocomplete(result[:128],n_generate=256, max_ctx=128)))\n",
    "print(more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gibberish.txt', 'w') as outfile:\n",
    "    outfile.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def foo():\n",
    "    global result\n",
    "    more = ''.join(list(trainer.autocomplete(n_generate=256, max_ctx=128)))\n",
    "    result += more\n",
    "    with open('gibberish.txt', 'a') as outfile:\n",
    "        outfile.write(more)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79670963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2400):\n",
    "    sleep(15)\n",
    "    t = asyncio.create_task(foo())\n",
    "    await t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8baa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.metrics[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(\"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load('checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "### SmoothPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "def smoother(X, Y, lag):\n",
    "    Y = np.cumsum(Y)\n",
    "    return X[lag:], (Y[lag:] - Y[:-lag])/lag\n",
    "\n",
    "def gsmoother(X, Y, lag):\n",
    "    X = X[lag:-lag]\n",
    "    Y = scipy.ndimage.gaussian_filter1d(Y, sigma=lag)[lag:-lag]\n",
    "    return (X, Y)\n",
    "\n",
    "class SmoothPlot(LinePlot):\n",
    "    def __init__(self, trainer, lag=100, log=None):\n",
    "        L = np.array([[x['step'],x['mean_loss']] for x in trainer.metrics])\n",
    "        n = len(L[:,0])\n",
    "        k = n//1000 + 1\n",
    "        X = L[:,0]\n",
    "        Y = L[:,1]\n",
    "        X,Y = gsmoother(X, Y, lag)\n",
    "        X = X[::k]\n",
    "        Y = Y[::k]\n",
    "        if log:\n",
    "            X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)\n",
    "\n",
    "class GaussianSmoothedLossRate(LinePlot):\n",
    "    def __init__(self, trainer, lag=100, log=None):\n",
    "        L = np.array([[x['step'],x['mean_loss']] for x in trainer.metrics])\n",
    "        X = L[1:,0]\n",
    "        Y = -L[1:,1] + L[:-1,1]\n",
    "        X,Y = gsmoother(X, Y, lag)\n",
    "        if log:\n",
    "            X = np.log(X)/math.log(2)\n",
    "        super().__init__(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmoothPlot(trainer, lag=10, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianSmoothedLossRate(trainer, lag=10000, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9414477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
