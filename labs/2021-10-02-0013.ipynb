{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4a24ab",
   "metadata": {},
   "source": [
    "# Lab Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12749494",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import GutenbergSnippetsDataset\n",
    "from classroom import MLPLM, MyLM\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2Sum\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel\n",
    "from classroom import utf8decode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa77de2",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c6c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    path = '2021-10-02-0013.pt'\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d536de8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = (\n",
    "        MLPLM(\n",
    "            n_ctx=512,\n",
    "            n_vocab_in=256,\n",
    "            d_model=8,\n",
    "            d_hidden=[8192, 4096, 8192, 4096],\n",
    "            nonlinearity=\"GELU\",\n",
    "            n_vocab_out=256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9963c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numel(model), numel(model)*4/1E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7497483",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model)*3*2.09*2048/1E12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed9ec4",
   "metadata": {},
   "source": [
    "## initialize student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44e13f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergSnippetsDataset()\n",
    "batch_size = None\n",
    "example_length = model.n_ctx + 1\n",
    "student= Student(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d10566",
   "metadata": {},
   "source": [
    "## schedule hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25468e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "student.batch_size=8192\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    batch_multiplier = 1\n",
    "    lr_base = 1e-9\n",
    "    lr = lambda n: lr_base * (n%1000) #* cos(3.14159*n/batch_multiplier/256)**2\n",
    "    student.optimizer.state[pn][\"lr\"]           = lambda n: lr(n)\n",
    "    student.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    student.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    student.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001\n",
    "    student.optimizer.state[pn][\"update\"]       = lambda n: n%batch_multiplier == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c6bd0",
   "metadata": {},
   "source": [
    "## initialize baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae8b7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "student.reset_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25202dea",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16854e92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classroom = Classroom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88848bd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classroom.enroll(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a761c7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def autocomplete(prompt=None):\n",
    "    if prompt is None:\n",
    "        prompt = student.dataset.decode(student.dataset.batch(1, 768).tolist()[0])\n",
    "    print(student.autocomplete(prompt=prompt, n_generate=1024, temp=1.0))\n",
    "autocomplete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "lag = 2048\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Count(), student.times)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), student.grades)\n",
    "    Z = Fun(TwoWindowFilter(lag=lag), student.baseline_grades)\n",
    "    plot_data.update({f\"grades-{idx}\": (X, Y)})\n",
    "    plot_data.update({f\"baseline-{idx}\": (X, Z)})\n",
    "Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86748c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270a92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data_2 = {}\n",
    "lag = 50\n",
    "for (idx, student) in enumerate(classroom.students):\n",
    "    X = Fun(Count(), student.times)\n",
    "    Y = Fun(lambda x, y: x - y, student.grades, student.baseline_grades)\n",
    "    Y = Fun(TwoWindowFilter(lag=lag), Y.output, aux=Y)\n",
    "    plot_data_2.update({f\"improvement-{idx}\": (X, Y)})\n",
    "Plot(**plot_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c32f3b",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (idx, student) in enumerate(classroom.students):\n",
    "    print(f\"\\nStudent #{idx}\\n==========\")\n",
    "    N = 500\n",
    "    n = len(student.times)-1\n",
    "    time = student.time\n",
    "    mean_grade = np.mean(np.array(student.grades[n-N:n]))\n",
    "    mean_baseline_grade = np.mean(np.array(student.baseline_grades[n-N:n]))\n",
    "    mean_improvement = mean_grade - mean_baseline_grade\n",
    "    improvement_rate = mean_improvement / (time - student.time_of_last_baseline)\n",
    "    message = '\\n'.join([\n",
    "        f\"lr                    = {student.optimizer.state['language_model.module.layers.0.weight']['lr'](n)}\",\n",
    "        f\"batch_size            = {student.batch_size}\",\n",
    "        f\"example_length        = {student.example_length}\",\n",
    "        f\"n                     = {n}\",\n",
    "        f\"time                  = {int(time)}s\",\n",
    "        f\"time_of_last_baseline = {int(student.time_of_last_baseline)}s\",\n",
    "        f\"steps per second      = {(n/time)}\",\n",
    "        f\"mean_baseline_grade   = {mean_baseline_grade}\",\n",
    "        f\"mean_grade            = {mean_grade}\",\n",
    "        f\"mean_improvement      = {mean_improvement}\",\n",
    "        f\"improvement_rate      = {improvement_rate} per second\",\n",
    "        f\"time to 80            = {(.80-mean_grade)/improvement_rate/3600} hours\",\n",
    "    ])\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe9998",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c88c06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save(student.model, f='2021-10-02-0013.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e05f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lyles_constant = 9115131782/14818489608 #* log(50257)/log(65536)\n",
    "lyles_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c69aaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mg = 0.792844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971dd30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - mg) / lyles_constant * log(50257)  # gpt2natscale (for kaplan paper comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd7334",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - mg) * 8  #  bits per character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1453cea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "2**((1 - mg) * 8)  # perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bd9d9",
   "metadata": {},
   "source": [
    "## parameter histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6da8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        print(idx, pn, torch.sqrt(torch.var(p)).item())\n",
    "        Y, X = np.histogram(p.detach().cpu().numpy(), bins=int(sqrt(torch.numel(p))), density=True)\n",
    "        print(X.shape, Y.shape)\n",
    "        histograms.append(Plot(**{f\"hist-{idx}\": (X.tolist(), Y.tolist())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92345fea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histograms[4] # 3 7 9 13 15 21 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd932e",
   "metadata": {},
   "source": [
    "## batch-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149c525",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y, X = np.histogram(student.grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "V, U = np.histogram(student.baseline_grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "Plot(**{f\"grade-hist\": (X, Y), \"baseline\": (U, V)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e52587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.n_ctx, model.d_model, model.d_hidden, model.n_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e8670",
   "metadata": {},
   "source": [
    "## example-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a6829",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_graded_examples():\n",
    "    result = []\n",
    "    for batch_idx in range(16):\n",
    "        print(f\"batch_idx = {batch_idx}/256\")\n",
    "        x = student.dataset.batch(student.batch_size, student.example_length)\n",
    "        with torch.no_grad():\n",
    "            y = student.model(x)\n",
    "            x = x.cpu().numpy()\n",
    "            y = 1.0 - y.cpu().numpy()\n",
    "            result.append(np.concatenate([x, y], axis=1))\n",
    "    data = np.concatenate(result, axis=0)\n",
    "    result = data.tolist()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69f1e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graded_examples = get_graded_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b19424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(x[-1] for x in graded_examples)/len(graded_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b00e04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_grades = [[] for _ in range(64)]\n",
    "for example in graded_examples:\n",
    "    grade = example[-1]\n",
    "    for k in range(1,64):\n",
    "        if int(example[-k-1]) in [ord(' '), ord('\\n'), ord('\\r')]:\n",
    "            example_grades[k].append(grade)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05ef58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for k in range(64):\n",
    "    print(f\"{k}, {len(example_grades[k])}, {sum(example_grades[k])/(len(example_grades[k])+1)}\")\n",
    "    tot += len(example_grades[k])\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86197b41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "85680/524231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715135b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R = (0, 1)\n",
    "def XYFor(k):\n",
    "    es = example_grades[k]\n",
    "    bins = int(sqrt(len(es)))\n",
    "    Y, X = np.histogram(es, bins=bins, range=R, density=True)\n",
    "    return (X, Y)\n",
    "Plot(**{f\"examples-hist-{k}\": XYFor(k) for k in [1, 2, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdc907",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04797a40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(example_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cffc0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.7870894884999871)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7599c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.8)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f2127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.9)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45748779",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccd89a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.unpackbits(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea23ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
