{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fed699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sharker/github/scholar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from scholar.trainer import Trainer\n",
    "from scholar.dataset import GutenbergGPT2Dataset\n",
    "from scholar.model import TransformerLM\n",
    "from scholar.optimizer import AdamW\n",
    "from scholar.autocomplete import autocomplete\n",
    "from scholar import numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a0b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    path = '2021-12-09-2307.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c6c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ddfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = (\n",
    "        MLPLM(\n",
    "            n_vocab_in=256,\n",
    "            n_ctx=1024,\n",
    "            d_model=8,\n",
    "            d_hidden=[8196],\n",
    "            nonlinearity=\"GELU\",\n",
    "            n_vocab_out=256).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = (\n",
    "        MyLM(\n",
    "            n_vocab_in=50257,\n",
    "            n_ctx=65,\n",
    "            d_model=64,\n",
    "            n_layers=1,\n",
    "            d_hidden=256,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.00,\n",
    "            n_vocab_out=50257).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d536de8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = (\n",
    "        ABPCNLM(\n",
    "            n_vocab_in=256,\n",
    "            n_ctx=4096,\n",
    "            d_model=2,\n",
    "            n_layers=1,\n",
    "            d_hidden=2048,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.0,\n",
    "            n_vocab_out=256).to('cuda'))\n",
    "    #batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4af084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = (\n",
    "        TransformerLM(\n",
    "            n_vocab_in=50257,\n",
    "            n_vocab_out=50257,\n",
    "            n_ctx=1024,\n",
    "            d_model=1024,\n",
    "            d_k=32,\n",
    "            d_v=32,\n",
    "            n_heads=32,\n",
    "            d_hidden=4096,\n",
    "            n_layers=3).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44e13f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergGPT2Dataset()\n",
    "batch_size = None\n",
    "example_length = model.n_ctx + 1\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25468e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.batch_size = 1\n",
    "trainer.example_length = 1025\n",
    "for (idx, (pn, p)) in enumerate(trainer.model.named_parameters()):\n",
    "    batch_multiplier = 100\n",
    "    lr_base = 1e-5\n",
    "    warm_up = 0\n",
    "    lr = lambda n: 0 if n < warm_up else lr_base *(1 + (n%1000))/1000 # * (1.0 + 9.0*cos(n*3.14159/10000)**2)\n",
    "    trainer.optimizer.state[pn][\"lr\"]           = lambda n: lr(n)\n",
    "    trainer.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    trainer.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    trainer.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001\n",
    "    trainer.optimizer.state[pn][\"update\"]       = lambda n: (n < warm_up) or (n%batch_multiplier == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shaping:\n",
    "    def __init__(self):\n",
    "        self.alpha=0.5\n",
    "    def __call__(self, batch, losses):\n",
    "        x = torch.mean(losses[...,:-1])\n",
    "        y = torch.mean(losses[...,-1])\n",
    "        return (1-self.alpha)*x + self.alpha*y\n",
    "    \n",
    "shaping = Shaping()\n",
    "\n",
    "async def train(trainer):\n",
    "    trainer.losses = []\n",
    "    while True:\n",
    "        loss = trainer.step(shaping=shaping)\n",
    "        trainer.losses.append(loss)\n",
    "        await asyncio.sleep(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_task = asyncio.create_task(train(trainer))\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef798d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n0 = trainer.n\n",
    "t0 = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = trainer.n\n",
    "t = time.time() - t_start\n",
    "dn = n - n0\n",
    "dt = t - t0\n",
    "\n",
    "N = max(10, dn//20*10)\n",
    "print(f\"N = {N}\")\n",
    "K = 0\n",
    "L = np.mean(np.array(trainer.losses[n-N:n]))\n",
    "L0 = np.mean(np.array(trainer.losses[n0+K:n0+K+N]))\n",
    "dL = (L - L0)\n",
    "if False:\n",
    "    lyles_constant = 8 # utf8 version\n",
    "else:\n",
    "    lyles_constant = (9115131782/2)/14818489608 * log(50257)/log(256)*8\n",
    "\n",
    "bpc = lyles_constant*L\n",
    "rate = 2 * lyles_constant * -dL/dt * 14818489608 / 8\n",
    "message = '\\n'.join([\n",
    "    f\"bpc                  = {int(bpc*1e6)/1e6}\",\n",
    "    f\"batch_size           = {trainer.batch_size}\",\n",
    "    f\"example_length       = {trainer.example_length}\",\n",
    "    f\"n                    = {n} steps\",\n",
    "    f\"t                    = {int(t)} seconds\",\n",
    "    f\"n0                   = {n0} steps\",\n",
    "    f\"dn                   = {int(dn)} steps\",\n",
    "    f\"dt                   = {int(dt)} seconds\",\n",
    "    f\"dn/dt                = {(dn/dt)} steps per second\",\n",
    "    f\"L                    = {int(L*1e6)/1e6}\",\n",
    "    f\"L0                   = {int(L0*1e6)/1e6}\",\n",
    "    f\"new bytes            = {int(dt*rate/2**20/2)}MiB\",\n",
    "    f\"bytes left = {int(bpc/8*14818489608/2**20)}MiB\",\n",
    "    f\"progress {int((8-bpc)/8 *14818489608//1E6)/1000}E9/14.818E9\",\n",
    "    f\"learning rate: {int(rate/1024)} KiBps, {int(rate*3600/2**20)} MiBph\",\n",
    "    f\"feeding rate: {int(trainer.batch_size*trainer.example_length*dn/dt*2)} Bps\"\n",
    "])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab098beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"When first the opposition of fact and ideal grows fully visible, a spirit\n",
    "of fiery revolt, of fierce hatred of the gods, seems necessary to the\n",
    "assertion of freedom. To defy with Promethean constancy a hostile universe,\n",
    "to keep its evil always in view, always actively hated, to refuse no pain\n",
    "that the malice of Power can invent, appears to be the duty of all who will\n",
    "not bow before the inevitable. But indignation is still a bondage, for it\n",
    "compels our thoughts to be occupied with an evil world; and in the fierceness\n",
    "of desire from which rebellion springs there is a kind of self-assertion\n",
    "which it is necessary for the wise to overcome. Indignation is a submission\n",
    "of our thoughts, but not of our desires; the Stoic freedom in which wisdom\n",
    "consists is found in the submission of our desires, but not of our thoughts.\n",
    "From the submission of our desires springs the virtue of resignation; from\n",
    "the freedom of our thoughts springs the whole world of art and philosophy,\n",
    "and the vision of beauty by which, at last, we half reconquer the reluctant\n",
    "world.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0859fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = autocomplete(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    encode=dataset.encode,\n",
    "    decode=dataset.decode,\n",
    "    n_ctx=128,\n",
    "    temp=1.0,\n",
    "    device=\"cuda\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c88c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(trainer.model, f=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffb030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
