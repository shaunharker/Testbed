{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12749494",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af05649",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import math\n",
    "from math import log, sin, cos, tan, exp, sqrt, pi\n",
    "import time\n",
    "from random import randrange\n",
    "import torch\n",
    "import numpy as np\n",
    "from classroom import Classroom\n",
    "from classroom import Student\n",
    "from classroom import BytesDataset\n",
    "from classroom import GutenbergSnippetsDataset\n",
    "from classroom import GutenbergBitsDataset\n",
    "from classroom import GutenbergGPT2Dataset\n",
    "from classroom import MLPLM, MyLM, ABPCNLM\n",
    "from classroom import TransformerLM\n",
    "from classroom import AdamW\n",
    "from classroom import Sonny\n",
    "from classroom import Floyd\n",
    "from classroom import Plot\n",
    "from classroom import Fun\n",
    "from classroom import Count\n",
    "from classroom import Sum\n",
    "from classroom import Diff\n",
    "from classroom import Log2Sum\n",
    "from classroom import KalmanFilter1D\n",
    "from classroom import MedianFilter\n",
    "from classroom import TwoWindowFilter\n",
    "from classroom import numel\n",
    "from classroom import utf8decode, utf8encode, gpt2decode, gpt2encode\n",
    "from classroom import utf8bitsdecode, utf8bitsencode\n",
    "from pathlib import Path\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa77de2",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '2021-10-12-0537.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836c6c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    model = torch.load(path).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d536de8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    D = 10\n",
    "    model = (\n",
    "        ABPCNLM(\n",
    "            n_vocab_in=50257,\n",
    "            n_ctx=2**D,\n",
    "            d_model=8,\n",
    "            n_layers=2,\n",
    "            d_hidden=2**D,\n",
    "            nonlinearity=\"GELU\",\n",
    "            p_dropout=0.0,\n",
    "            n_vocab_out=50257).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9963c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numel(model), numel(model)*4/1E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7497483",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel(model)*3*2.09*2048/1E12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed9ec4",
   "metadata": {},
   "source": [
    "## initialize student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44e13f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(parameters=model.named_parameters())\n",
    "dataset = GutenbergGPT2Dataset()\n",
    "batch_size = None\n",
    "example_length = model.n_ctx + 1\n",
    "student= Student(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    example_length=example_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d10566",
   "metadata": {},
   "source": [
    "## schedule hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25468e2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "student.batch_size=1024\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    batch_multiplier = 32\n",
    "    lr_base = 1e-8\n",
    "    lr = lambda n: lr_base*(n%10000)\n",
    "    student.optimizer.state[pn][\"lr\"]           = lambda n: lr(n)\n",
    "    student.optimizer.state[pn][\"beta1\"]        = lambda n: 0.9\n",
    "    student.optimizer.state[pn][\"beta2\"]        = lambda n: 0.999\n",
    "    student.optimizer.state[pn][\"weight_decay\"] = lambda n: 0.001\n",
    "    student.optimizer.state[pn][\"update\"]       = lambda n: n%batch_multiplier == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310c6bd0",
   "metadata": {},
   "source": [
    "## initialize baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae8b7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    student.reset_baseline()\n",
    "    n_of_last_baseline = len(student.times)\n",
    "    t_start = time.time()\n",
    "    t_of_last_baseline = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25202dea",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16854e92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def train(student):\n",
    "    while True:\n",
    "        student.study()\n",
    "        await asyncio.sleep(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_task = asyncio.create_task(train(student))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33459961",
   "metadata": {},
   "source": [
    "## autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88519c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete(model, prompt=None, n_generate=512,\n",
    "                     n_ctx=None, temp=1.0,\n",
    "                     encode=None, decode=None, output=None):\n",
    "    Categorical = torch.distributions.Categorical\n",
    "    if n_ctx is None:\n",
    "        n_ctx = model.n_ctx\n",
    "    if encode is None:\n",
    "        encode = gpt2encode\n",
    "    if decode is None:\n",
    "        decode = gpt2decode\n",
    "    if prompt is None:\n",
    "        prompt = decode(student.dataset.batch(1, 2*n_ctx, offset=None).tolist()[0])  # kludge\n",
    "    x = encode(prompt)\n",
    "    x = x[-n_ctx:]\n",
    "    prompt = decode(x)\n",
    "    print(f\"=== Prompt ===\\n{prompt}\\n=== Autocompletion ===\\n\")\n",
    "\n",
    "    def sampler(x):\n",
    "        x = list(x)\n",
    "        for _ in range(n_generate):\n",
    "            probs = model.inference(torch.tensor(x, dtype=torch.long, device=\"cuda\").unsqueeze(0)).view(-1)[-model.n_vocab_out:]\n",
    "            if temp > 0:\n",
    "                y = Categorical(probs=probs**(1.0/temp)).sample().item()\n",
    "            else:\n",
    "                y = torch.argmax(probs).item()\n",
    "            x = (x + [y])[-n_ctx:]\n",
    "            if output is not None:\n",
    "                output.append(y)\n",
    "            yield y\n",
    "    result = decode(list(sampler(x)))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad26652",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autocomplete(model=student.model, temp=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67bcaf5",
   "metadata": {},
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b45bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data = {}\n",
    "lag = 100\n",
    "X = Fun(Log2Sum(), student.times)\n",
    "Y = Fun(TwoWindowFilter(lag=lag), student.grades)\n",
    "Z = Fun(TwoWindowFilter(lag=lag), student.baseline_grades)\n",
    "plot_data.update({f\"grades\": (X, Y)})\n",
    "plot_data.update({f\"baseline\": (X, Z)})\n",
    "# Plot(**plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152aa4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.model.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f86748c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "student.baseline.baseline_model.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab270a92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "plot_data_2 = {}\n",
    "lag = 1000\n",
    "X = Fun(Count(), student.times)\n",
    "Y = Fun(lambda x, y: x - y, student.grades, student.baseline_grades)\n",
    "Y = Fun(TwoWindowFilter(lag=lag), Y.output, aux=Y)\n",
    "plot_data_2.update({f\"improvement\": (X, Y)})\n",
    "Plot(**plot_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c32f3b",
   "metadata": {},
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n = len(student.times)-1\n",
    "t = time.time() - t_start\n",
    "dn = n - n_of_last_baseline\n",
    "dt = t - t_of_last_baseline\n",
    "\n",
    "N = min(1000, dn//2)\n",
    "\n",
    "y = np.mean(np.array(student.grades[n-N:n]))\n",
    "y0 = np.mean(np.array(student.baseline_grades[n-N:n]))\n",
    "dy = y - y0\n",
    "\n",
    "message = '\\n'.join([\n",
    "    f\"batch_size            = {student.batch_size}\",\n",
    "    f\"example_length        = {student.example_length}\",\n",
    "    f\"100*y                 = {int(y*1e6)/1e4}\",\n",
    "    f\"n                     = {n} steps\",\n",
    "    f\"t                     = {int(t)} seconds\",\n",
    "    f\"n_of_last_baseline    = {n_of_last_baseline} steps\",\n",
    "    f\"t_of_last_baseline    = {int(t_of_last_baseline)} seconds\",\n",
    "    f\"steps per second      = {dn/dt}\",\n",
    "    f\"y0                    = {int(y0*1e6)/1e6}\",\n",
    "    f\"dy                    = {int(dy*1e6)/1e6}\",\n",
    "    f\"dn                    = {dn}\",\n",
    "    f\"dt                    = {dt}\",\n",
    "    f\"dy/dn                 = {dy/dn}\",\n",
    "    f\"dy/dt                 = {int(1e8 * dy/dt)}e-8 per second\",\n",
    "    f\"time to 71            = {(.71-y)/(dy/dt)/3600} hours\",\n",
    "])\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3993253",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    student.reset_baseline()\n",
    "    n_of_last_baseline = len(student.times)-1\n",
    "    t_of_last_baseline = time.time() - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe9998",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c88c06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save(student.model, f=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "async def autosave():\n",
    "    while True:\n",
    "        await asyncio.sleep(3600)\n",
    "        torch.save(student.model, f='autosave.pt')\n",
    "task = asyncio.create_task(autosave())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e05f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lyles_constant = 9115131782/14818489608 #* log(50257)/log(65536)\n",
    "lyles_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfeaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "utf8grade = lambda x: 1 - (1 - x)*lyles_constant\n",
    "grade = .655\n",
    "print(f\"gpt2 grade = {grade}, utf8 grade = {utf8grade(grade)}, bpc = {(1-utf8grade(grade))*8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bd9d9",
   "metadata": {},
   "source": [
    "## parameter histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6da8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for (idx, (pn, p)) in enumerate(student.model.named_parameters()):\n",
    "    with torch.no_grad():\n",
    "        print(idx, pn, torch.sqrt(torch.var(p)).item())\n",
    "        Y, X = np.histogram(p.detach().cpu().numpy(), bins=int(sqrt(torch.numel(p))), density=True)\n",
    "        print(X.shape, Y.shape)\n",
    "        histograms.append(Plot(**{f\"hist-{idx}\": (X.tolist(), Y.tolist())}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92345fea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "histograms[4] # 3 7 9 13 15 21 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd932e",
   "metadata": {},
   "source": [
    "## batch-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149c525",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y, X = np.histogram(student.grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "V, U = np.histogram(student.baseline_grades[-5000:], bins=256, range=(0,1.0), density=True)\n",
    "Plot(**{f\"grade-hist\": (X, Y), \"baseline\": (U, V)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e52587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.n_ctx, model.d_model, model.d_hidden, model.n_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e8670",
   "metadata": {},
   "source": [
    "## example-level grade histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a6829",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_graded_examples():\n",
    "    result = []\n",
    "    for batch_idx in range(16):\n",
    "        print(f\"batch_idx = {batch_idx}/256\")\n",
    "        x = student.dataset.batch(student.batch_size, student.example_length)\n",
    "        print(f\"orig {x.shape}\")\n",
    "        with torch.no_grad():\n",
    "            y = student.model(x)\n",
    "            y = 1.0 - y.cpu().numpy()\n",
    "            result.append(y)\n",
    "    data = np.concatenate(result, axis=0)\n",
    "    result = data.tolist()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc69f1e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graded_examples = get_graded_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41830fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graded_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b19424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum(x for x in graded_examples)/len(graded_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715135b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R = (0, 1)\n",
    "def XYFor(k):\n",
    "    es = graded_examples\n",
    "    bins = int(sqrt(len(es)))\n",
    "    Y, X = np.histogram(es, bins=bins, range=R, density=True)\n",
    "    return (X, Y)\n",
    "Plot(**{f\"examples-hist-{k}\": XYFor(k) for k in [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdc907",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ord(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04797a40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(example_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cffc0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.7870894884999871)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd7599c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.8)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f2127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(1 - 0.9)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45748779",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ccd89a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.unpackbits(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea23ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
